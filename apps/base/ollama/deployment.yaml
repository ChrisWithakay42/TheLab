apiVersion: apps/v1
kind: Deployment
metadata:
  name: ollama
  namespace: ollama
  labels:
    app: ollama
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ollama
  template:
    metadata:
      labels:
        app: ollama
    spec:
      nodeSelector:
        role: ai-host
      initContainers:
      - name: ollama-pull
        image: ollama/ollama
        command:
        - "/bin/sh"
        - "-c"
        - |
          ollama serve &
          OLLAMA_PID=$!
          echo "Waiting for Ollama server to start..."
          until ollama list; do
            echo -n "."
            sleep 1
          done
          echo "Ollama server started. Pulling models..."
          ollama pull qwen2.5-coder:7b
          ollama pull codellama:7b
          ollama pull 0xroyce/plutus
          ollama pull martain7r/finance-llama-8b:q4_k_m
          ollama pull deepseek-coder:6.7b
          ollama pull gemma:2b
          echo "Finished pulling models. Stopping server."
          kill $OLLAMA_PID
          wait $OLLAMA_PID
        volumeMounts:
        - name: ollama-data
          mountPath: /root/.ollama
      containers:
        - name: ollama
          image: ollama/ollama
          ports:
            - containerPort: 11434
              name: http
          volumeMounts:
            - name: ollama-data
              mountPath: /root/.ollama
          resources:
            requests:
              cpu: "2"
              memory: "16Gi"
            limits:
              cpu: "4"
              memory: "32Gi"
      volumes:
        - name: ollama-data
          persistentVolumeClaim:
            claimName: ollama-pvc
